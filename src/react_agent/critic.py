"""Define a Critic Agent for evaluating Odoo 18 generated code.

This module implements a code evaluation agent using OpenEvals to assess
code quality, correctness, and adherence to Odoo standards.
"""

from typing import Dict, List, Optional, Any

from langchain_core.messages import AIMessage, HumanMessage
from openevals.llm import create_llm_as_judge

from react_agent.configuration import Configuration
from react_agent.state import State
import asyncio

# Define Odoo-specific evaluation prompts
ODOO_CODE_QUALITY_PROMPT = """
You are an expert Odoo developer tasked with evaluating the quality of Odoo 18 code.
You will be given a piece of code and need to evaluate it based on the following criteria:

1. Adherence to Odoo coding standards and conventions
2. Proper use of Odoo ORM methods and APIs
3. Code organization and structure
4. Readability and maintainability
5. Performance considerations
6. Security best practices

Code to evaluate:
{outputs}

Please provide a detailed assessment of the code quality, highlighting both strengths and areas for improvement.
Your evaluation should be specific to Odoo 18 development practices.

Score the code on a scale of 1-10, where 1 is poor quality and 10 is excellent quality.
Provide your score as a number followed by a detailed explanation.
"""

ODOO_CORRECTNESS_PROMPT = """
You are an expert Odoo developer tasked with evaluating the correctness of Odoo 18 code.
You will be given a piece of code and need to evaluate it based on the following criteria:

1. Functional correctness (does the code do what it's supposed to do?)
2. Proper use of Odoo APIs and methods
3. Handling of edge cases and errors
4. Compatibility with Odoo 18 specifically

**Additional Considerations:**
- Implement `mail.thread` integration for chatter functionality.
- Follow Odoo 18 view guidelines (use `list` instead of `tree`).
- Replace deprecated `attrs` with Odoo 18-compatible options.
- Ensure security, error handling, and thorough testing.

Code to evaluate:
{outputs}

Please provide a detailed assessment of the code correctness, highlighting any issues or bugs.
Your evaluation should be specific to Odoo 18 development practices.

Score the code on a scale of 1-10, where 1 is incorrect and 10 is perfectly correct.
Provide your score as a number followed by a detailed explanation.
"""


async def evaluate_code(state: State) -> Dict[str, List[AIMessage]]:
    """Evaluate the code generated by the agent using OpenEvals.
    
    This function extracts code from the conversation, evaluates it using
    OpenEvals LLM-as-judge evaluators, and returns feedback.
    
    Args:
        state (State): The current state of the conversation.
        
    Returns:
        dict: A dictionary containing the evaluation feedback message.
    """
    configuration = Configuration.from_context()
    
    # Extract code from the conversation
    code_to_evaluate = extract_code_from_messages(state.messages)
    
    if not code_to_evaluate:
        return {
            "messages": [
                AIMessage(
                    content="No code found to evaluate. Please generate some Odoo code first."
                )
            ]
        }
    
    # Create evaluators using OpenEvals
    quality_evaluator = create_llm_as_judge(
        prompt=ODOO_CODE_QUALITY_PROMPT,
        model=configuration.model,
    )
    
    correctness_evaluator = create_llm_as_judge(
        prompt=ODOO_CORRECTNESS_PROMPT,
        model=configuration.model,
    )
    
    # Run evaluations
    quality_result = await asyncio.to_thread(lambda: quality_evaluator(outputs=code_to_evaluate))
    correctness_result = await asyncio.to_thread(lambda: correctness_evaluator(outputs=code_to_evaluate))        
    
    # Format feedback
    feedback = f"""## Code Evaluation Feedback

### Quality Assessment
{quality_result.get('comment', 'No quality feedback available.')}

### Correctness Assessment
{correctness_result.get('comment', 'No correctness feedback available.')}

### Recommendations
Based on the above assessments, consider making the following improvements to your code:

1. {generate_recommendation(quality_result, correctness_result, 1)}
2. {generate_recommendation(quality_result, correctness_result, 2)}
3. {generate_recommendation(quality_result, correctness_result, 3)}
"""
    
    return {
        "messages": [
            AIMessage(
                content=feedback
            )
        ]
    }


def extract_code_from_messages(messages: List[Any]) -> Optional[str]:
    """Extract code blocks from the conversation messages.
    
    Args:
        messages: List of conversation messages.
        
    Returns:
        str or None: Extracted code or None if no code is found.
    """
    code_blocks = []
    
    for message in messages:
        if isinstance(message, AIMessage) and not message.tool_calls:
            content = message.content
            # Simple extraction of code blocks between triple backticks
            if isinstance(content, str):
                code_start = content.find("```")
                while code_start != -1:
                    code_start += 3
                    # Skip language identifier if present
                    if content[code_start:].find("\n") != -1:
                        code_start = content.find("\n", code_start) + 1
                    
                    code_end = content.find("```", code_start)
                    if code_end != -1:
                        code_blocks.append(content[code_start:code_end].strip())
                        content = content[code_end + 3:]
                        code_start = content.find("```")
                    else:
                        break
    
    return "\n\n".join(code_blocks) if code_blocks else None


def generate_recommendation(quality_result: Dict[str, Any], correctness_result: Dict[str, Any], index: int) -> str:
    """Generate a specific recommendation based on evaluation results.
    
    Args:
        quality_result: Results from the quality evaluation.
        correctness_result: Results from the correctness evaluation.
        index: Index of the recommendation to generate.
        
    Returns:
        str: A recommendation for improving the code.
    """
    # Extract comments from results
    quality_comment = quality_result.get('comment', '')
    correctness_comment = correctness_result.get('comment', '')
    
    # Default recommendations if specific ones can't be extracted
    default_recommendations = [
        "Ensure your code follows Odoo's naming conventions and structure.",
        "Use Odoo ORM methods instead of direct SQL queries when possible.",
        "Add proper docstrings and comments to improve code maintainability."
    ]
    
    # Try to extract specific recommendations from the comments
    # This is a simple implementation and could be improved with more sophisticated NLP
    if index <= len(default_recommendations):
        return default_recommendations[index - 1]
    else:
        return "Review the feedback above and make appropriate improvements."